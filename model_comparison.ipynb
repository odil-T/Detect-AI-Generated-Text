{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe4edf-1577-4c8a-9288-fe73ba8fde23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file trains different models with different text representation techniques and compares their F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2efa1de5-4642-49bf-a8c6-ea925794f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f255b-d49a-4bc6-81e9-4c0eb4cd7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/compiled_processed_train_data.csv')\n",
    "val_data = pd.read_csv('data/compiled_processed_val_data.csv')\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "bow_vectorizer = CountVectorizer()\n",
    "uni_bi_gram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# initializing text representation features\n",
    "for rep, vectorizer in zip(['bow', 'uni_bi_gram', 'tfidf'], [bow_vectorizer, uni_bi_gram_vectorizer, tfidf_vectorizer]):\n",
    "    train_data[rep] = vectorizer.fit_transform(train_data['processed_text']).toarray().tolist()\n",
    "    val_data[rep] = vectorizer.transform(val_data['processed_text']).toarray().tolist()\n",
    "\n",
    "for data in (train_data, val_data):\n",
    "    data['word2vec_doc'] = data['text'].apply(lambda text: nlp(text).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "be576366-2470-495c-869d-4f7e7fec637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegression()\n",
    "model_rf = RandomForestClassifier()\n",
    "model_gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a00508ca-e321-4d06-b70e-fce4daa5ae3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odil\\PycharmProjects\\LLM - Detect AI Generated Text Kaggle Competition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - LogisticRegression() | Representation - bow\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       0.99      0.99      0.99       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odil\\PycharmProjects\\LLM - Detect AI Generated Text Kaggle Competition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - LogisticRegression() | Representation - uni_bi_gram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       0.99      0.99      0.99       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - LogisticRegression() | Representation - tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       1.00      0.99      1.00       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odil\\PycharmProjects\\LLM - Detect AI Generated Text Kaggle Competition\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - LogisticRegression() | Representation - word2vec_doc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       1.00      0.99      1.00       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - RandomForestClassifier() | Representation - bow\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       1.00      0.99      1.00       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - RandomForestClassifier() | Representation - uni_bi_gram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       1.00      0.99      1.00       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - RandomForestClassifier() | Representation - tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       1.00      0.99      1.00       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - RandomForestClassifier() | Representation - word2vec_doc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       275\n",
      "           1       1.00      0.99      0.99       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      0.99      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - GradientBoostingClassifier() | Representation - bow\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       0.99      0.99      0.99       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - GradientBoostingClassifier() | Representation - uni_bi_gram\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       1.00      0.99      1.00       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - GradientBoostingClassifier() | Representation - tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       0.99      0.99      0.99       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n",
      "Model - GradientBoostingClassifier() | Representation - word2vec_doc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       275\n",
      "           1       0.99      0.99      0.99       161\n",
      "\n",
      "    accuracy                           1.00       436\n",
      "   macro avg       1.00      1.00      1.00       436\n",
      "weighted avg       1.00      1.00      1.00       436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train = train_data.generated\n",
    "y_val = val_data.generated\n",
    "\n",
    "for model in (model_logistic, model_rf, model_gb):\n",
    "    for rep in ('bow', 'uni_bi_gram', 'tfidf', 'word2vec_doc'):\n",
    "        # flattening text representation column from lists into separate columns\n",
    "        X_train = pd.concat([train_data['prompt_id'], train_data[rep].apply(lambda x: pd.Series(x))], axis=1)\n",
    "        X_train.columns = X_train.columns.astype(str)\n",
    "        X_val = pd.concat([val_data['prompt_id'], val_data[rep].apply(lambda x: pd.Series(x))], axis=1)\n",
    "        X_val.columns = X_val.columns.astype(str)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        print(f'Model - {model} | Representation - {rep}')\n",
    "        print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea8e22-23a8-466c-8060-d4a722d28489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
